# Databricks notebook for transforming sales data

from pyspark.sql.functions import col

# Load data
df = spark.read.csv("abfss://raw@salesadls.dfs.core.windows.net/sales/sample_sales_data.csv", header=True, inferSchema=True)

# Clean and transform
df_clean = df.withColumn("Revenue", col("Quantity") * col("Unit_Price"))

# Save to gold layer
df_clean.write.mode("overwrite").parquet("abfss://gold@salesadls.dfs.core.windows.net/sales/cleaned_sales_data")
